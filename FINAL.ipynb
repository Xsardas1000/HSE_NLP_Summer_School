{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "import codecs\n",
    "import itertools  \n",
    "import string\n",
    "import os, re, fnmatch\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_lines(lines):\n",
    "    formatted = []\n",
    "    for line in lines[18:]:\n",
    "        parts = line.split(',')\n",
    "        formatted.append(parts[:4])\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_sent_dict(path):\n",
    "    sent_words = defaultdict(list)\n",
    "    with codecs.open(path,'r',encoding='cp1251') as f:\n",
    "        print(f.encoding)\n",
    "        lines = f.readlines()\n",
    "    #for line in lines:\n",
    "    #    print(line)\n",
    "    formatted = format_lines(lines)\n",
    "    words = dict(word = [], tone = [], part = [])\n",
    "    \n",
    "    for line in formatted:\n",
    "        words['word'].append(line[0].strip())\n",
    "        words['tone'].append(line[1].strip())\n",
    "        words['part'].append(line[3].strip())\n",
    "        sent_words[line[0].strip()] = [line[1].strip(), line[3].strip()]\n",
    "    #print(pd.DataFrame(words))\n",
    "    return sent_words, pd.DataFrame(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp1251\n",
      "['Adj', 'negative']\n"
     ]
    }
   ],
   "source": [
    "sent_words, words = make_sent_dict('RuSentiLex2017_revised_2.txt')\n",
    "print(sent_words['гадкий'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_paths(source_path, mask):\n",
    "    find_files = []\n",
    "    for root, dirs, files in os.walk(source_path):\n",
    "        find_files += [os.path.join(root, name) for name in files if fnmatch.fnmatch(name, mask)]\n",
    "    return find_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_source_paths(dirname, mod):\n",
    "    file_paths = []\n",
    "    opin_paths = []\n",
    "    ann_paths = []\n",
    "    for i in range(100):\n",
    "        path = get_file_paths(dirname, 'art' + str(i) + '.txt')\n",
    "        if len(path) > 0:\n",
    "            file_paths.append(path[0])\n",
    "    for path in file_paths:\n",
    "        idx = path[len(dirname) + 3:-4]\n",
    "        #print(path, idx)\n",
    "        ann_paths.append(dirname + 'art' + str(idx) + '.ann')\n",
    "    if mod == \"train\":\n",
    "        for path in file_paths:\n",
    "            idx = path[len(dirname) + 3:-4]\n",
    "            opin_paths.append(dirname + 'art' + str(idx) + '.opin.txt')\n",
    "    if mod == \"test\":\n",
    "        return file_paths, ann_paths\n",
    "    return file_paths, opin_paths, ann_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths, opin_paths, ann_paths = get_source_paths(\"Texts/\", mod=\"train\")\n",
    "#opin_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = [a for a in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_text(text):\n",
    "    snts = text.replace('\\n', '').split('{Author, Unknown}')\n",
    "    snts = [snt for snt in snts if len(snt) > 5]    \n",
    "    norm_snts = []\n",
    "    for sent in snts:\n",
    "        for k in l:\n",
    "            sent = sent.replace(k, ' ')\n",
    "        words = simple_word_tokenize(sent)\n",
    "        words = [word for word in words if len(word) > 0]\n",
    "        words = [morph.parse(word)[0].normal_form for word in words]\n",
    "        norm_snts.append(' '.join(words))\n",
    "    return norm_snts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_sample(sample, pairs):\n",
    "    for pair in pairs:\n",
    "        if (pair[0] == sample[1] and pair[1] == sample[0]) or (pair[0] == sample[0] and pair[1] == sample[1]):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_sample((\"aa\", \"bb\"), [(\"tt\", \"rr\"), (\"bb\", \"aa\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_file_dict(text, dd, sent_words):\n",
    "    slovar = dict(first = [], second = [], num_neg = [], num_pos = [], sent = [], ans = [])\n",
    "    norm_snts = prepare_text(text)\n",
    "    #print(norm_snts)\n",
    "    \n",
    "    entity_pairs_train = []\n",
    "    for idx, row in dd.iterrows():\n",
    "        entity_pairs_train.append((row[0].strip(), row[1].strip(), row[2].strip()))\n",
    "        \n",
    "    #print(entity_pairs_train)\n",
    "    filtered_entities = [] \n",
    "    for pair in entity_pairs_train:\n",
    "        if find_sample(pair, filtered_entities) == False:\n",
    "            filtered_entities.append(pair)\n",
    "            \n",
    "    #print(filtered_entities)\n",
    "    for first_entity, second_entity, tag in entity_pairs_train: #!entity_pairs_train-> filtered_entities\n",
    "        first_entity = morph.parse(first_entity)[0].normal_form\n",
    "        second_entity = morph.parse(second_entity)[0].normal_form\n",
    "        for sent in norm_snts:\n",
    "            #print(first_entity, second_entity, row[2])\n",
    "            #print(sent)            \n",
    "            if first_entity in sent and second_entity in sent:\n",
    "                #print(sent)\n",
    "                num_neg = 0\n",
    "                num_pos = 0\n",
    "                for word in sent.split(' '):\n",
    "                    #print(word)\n",
    "                    if len(sent_words[word]) != 2:\n",
    "                        continue\n",
    "                    if sent_words[word][1] == 'negative':\n",
    "                        num_neg += 1\n",
    "                    if sent_words[word][1] == 'positive':\n",
    "                        num_pos += 1\n",
    "                \n",
    "                #if num_pos == 0 and num_neg == 0:\n",
    "                #    continue\n",
    "                \n",
    "                slovar['sent'].append(sent)\n",
    "                slovar['ans'].append(tag)\n",
    "                slovar['first'].append(first_entity)\n",
    "                slovar['second'].append(second_entity)\n",
    "                slovar['num_neg'].append(num_neg)\n",
    "                slovar['num_pos'].append(num_pos)\n",
    "\n",
    "    #print(slovar.items())\n",
    "    filtered_slovar = []\n",
    "    \n",
    "    '''for line in zip(slovar['first'], slovar['second'], slovar['ans'], slovar['sent'], slovar['num_neg'], slovar['num_pos']):\n",
    "        #print(first, second, ans, sent, num_neg, num_pos)\n",
    "        if find_sample(line, filtered_slovar) == True:\n",
    "            filtered_slovar = splash(line, filtered_slovar)\n",
    "        else:\n",
    "            filtered_slovar.append(line)\n",
    "            \n",
    "    #print(filtered_slovar)  \n",
    "    slovar = dict(first = [], second = [], num_neg = [], num_pos = [], sent = [], ans = [])\n",
    "    for first, second, ans, sent, num_neg, num_pos in filtered_slovar: \n",
    "        #print(first, second, ans, sent, num_neg, num_pos)\n",
    "        slovar['first'].append(first)\n",
    "        slovar['second'].append(second)\n",
    "        slovar['ans'].append(ans)\n",
    "        slovar['sent'].append(sent)\n",
    "        slovar['num_neg'].append(num_neg)\n",
    "        slovar['num_pos'].append(num_pos)\n",
    "    '''   \n",
    "    return pd.DataFrame(slovar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splash(sample, filtered_slovar):\n",
    "    new_slovar = []\n",
    "    for pair in filtered_slovar:\n",
    "        if (pair[0] == sample[1] and pair[1] == sample[0]) or (pair[0] == sample[0] and pair[1] == sample[1]):\n",
    "            new_slovar.append((pair[0], pair[1], pair[2], pair[3] + sample[3], pair[4] + sample[4], pair[5] + sample[5]))\n",
    "        else:\n",
    "            new_slovar.append(pair)\n",
    "    return new_slovar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splash_test(sample, filtered_slovar):\n",
    "    new_slovar = []\n",
    "    for pair in filtered_slovar:\n",
    "        if (pair[0] == sample[1] and pair[1] == sample[0]) or (pair[0] == sample[0] and pair[1] == sample[1]):\n",
    "            new_slovar.append((pair[0], pair[1], pair[2] + sample[2], pair[3] + sample[3], pair[4] + sample[4]))\n",
    "        else:\n",
    "            new_slovar.append(pair)\n",
    "    return new_slovar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_file_dict_test(text, entity_pairs, sent_words):\n",
    "    slovar = dict(sent = [], first = [], second = [], num_neg = [], num_pos = [])\n",
    "\n",
    "    norm_snts = prepare_text(text)\n",
    "    filtered_entities = [] \n",
    "    for pair in entity_pairs:\n",
    "        if find_sample(pair, filtered_entities) == False:\n",
    "            filtered_entities.append(pair)    \n",
    "    for first_entity, second_entity in filtered_entities:\n",
    "        #print(first_entity, second_entity)\n",
    "        for sent in norm_snts:\n",
    "            if first_entity in sent and second_entity in sent:\n",
    "                num_neg = 0\n",
    "                num_pos = 0\n",
    "                for word in sent.split(' '):\n",
    "                    if len(sent_words[word]) != 2:\n",
    "                        continue\n",
    "                    if sent_words[word][1] == 'negative':\n",
    "                        num_neg += 1\n",
    "                    if sent_words[word][1] == 'positive':\n",
    "                        num_pos += 1\n",
    "                        \n",
    "                #if num_pos == 0 and num_neg == 0:\n",
    "                #    continue\n",
    "                        \n",
    "                slovar['sent'].append(sent)\n",
    "                slovar['first'].append(first_entity)\n",
    "                slovar['second'].append(second_entity)\n",
    "                slovar['num_neg'].append(num_neg)\n",
    "                slovar['num_pos'].append(num_pos)\n",
    "    \n",
    "    filtered_slovar = [] \n",
    "    for line in zip(slovar['first'], slovar['second'], slovar['sent'], slovar['num_neg'], slovar['num_pos']):\n",
    "        if find_sample(line, filtered_slovar) == True:\n",
    "            filtered_slovar = splash_test(line, filtered_slovar)\n",
    "        else:\n",
    "            filtered_slovar.append(line)\n",
    "            \n",
    "    #print(filtered_slovar)  \n",
    "    slovar = dict(first = [], second = [], num_neg = [], num_pos = [], sent = [])\n",
    "    for first, second, sent, num_neg, num_pos in filtered_slovar: \n",
    "        slovar['first'].append(first)\n",
    "        slovar['second'].append(second)\n",
    "        slovar['sent'].append(sent)\n",
    "        slovar['num_neg'].append(num_neg)\n",
    "        slovar['num_pos'].append(num_pos)\n",
    "    \n",
    "    return pd.DataFrame(slovar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_entities(path):\n",
    "    ann_file = pd.read_csv(path, sep='\\t', header = None)\n",
    "    ann_file.columns = ['Term', 'Type', 'Name']\n",
    "\n",
    "    digits = []\n",
    "    for i in range(len(ann_file.loc[:, 'Type'])):\n",
    "        string = ann_file.loc[i, 'Type']\n",
    "        digits.append(re.findall('\\d+', string))\n",
    "        idx = string.find(re.findall('\\d+', string)[0])\n",
    "        ann_file.loc[i, 'Type'] = string[:idx]\n",
    "    \n",
    "    for i in range(len(ann_file.loc[:, 'Name'])):\n",
    "        string = ann_file.loc[i, 'Name']\n",
    "        lemma = morph.parse(string)[0]\n",
    "        ann_file.loc[i, 'Name'] = lemma.normal_form    \n",
    "    \n",
    "    dgts = pd.DataFrame(digits, columns=['BeginPos', 'EndPos'])\n",
    "    ann_file['BeginPos'], ann_file['EndPos'] = dgts.loc[:, 'BeginPos'], dgts.loc[:, 'EndPos']\n",
    "    ann_file.drop('Term', inplace=True, axis=1)\n",
    "\n",
    "    for i in range(len(ann_file)):\n",
    "        if ann_file.loc[i, 'Name'] == 'author' or ann_file.loc[i, 'Name'] == 'unknown':\n",
    "            ann_file.loc[i, 'Name'] = np.NaN\n",
    "        \n",
    "    ann_file.dropna(inplace=True)\n",
    "    ann_file.index = range(ann_file.shape[0])\n",
    "    return ann_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = [a for a in string.punctuation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analize_files(file_paths, opin_paths, sent_words):\n",
    "    spisok = []\n",
    "    for path, opin in zip(file_paths, opin_paths):\n",
    "        with open(path,'r') as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        dd = pd.read_csv(opin, header = None).drop(3, axis = 1)\n",
    "        \n",
    "        #print(dd)\n",
    "        #print(make_file_dict(text, dd, sent_words))\n",
    "        spisok.append(make_file_dict(text, dd, sent_words))\n",
    "        result = pd.concat(spisok, ignore_index=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analize_files_test(file_paths, ann_paths, sent_words):\n",
    "    spisok = []\n",
    "    test_data = list(zip(file_paths, ann_paths))\n",
    "    for path, ann_path in tqdm(test_data):\n",
    "        with open(path,'r') as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        ann_df = get_entities(ann_path)\n",
    "        entities = list(set(ann_df['Name'].tolist()))\n",
    "        #print(len(entities))\n",
    "        entities = [' '.join([morph.parse(word)[0].normal_form for word in entity.split(' ')]) for entity in entities]\n",
    "        \n",
    "        entity_pairs = list(itertools.combinations(entities, 2))\n",
    "        #print(entity_pairs)\n",
    "        spisok.append(make_file_dict_test(text, entity_pairs, sent_words))\n",
    "        result = pd.concat(spisok, ignore_index=True)\n",
    "    return spisok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = analize_files(file_paths, opin_paths, sent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(878, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 42/42 [00:28<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "test = analize_files_test(file_paths, ann_paths, sent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ans</th>\n",
       "      <th>first</th>\n",
       "      <th>num_neg</th>\n",
       "      <th>num_pos</th>\n",
       "      <th>second</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>сша</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>игил</td>\n",
       "      <td>согласно заявление из пентагон цель сша — спос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>сирия</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>сша</td>\n",
       "      <td>беспокойство сша очевидно тот кто оказаться по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>россия</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>сша</td>\n",
       "      <td>инспирировать сша и поддержать европа « револю...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>россия</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>сша</td>\n",
       "      <td>последний отметить алеми наиболее откровенно в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>нато</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>россия</td>\n",
       "      <td>сми иран финляндия не хотеть вступать в нато и...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ans   first  num_neg  num_pos  second  \\\n",
       "0  neg     сша      0.0      2.0    игил   \n",
       "1  neg   сирия      3.0      2.0     сша   \n",
       "2  neg  россия      3.0      0.0     сша   \n",
       "3  neg  россия      2.0      0.0     сша   \n",
       "4  neg    нато      1.0      0.0  россия   \n",
       "\n",
       "                                                sent  \n",
       "0  согласно заявление из пентагон цель сша — спос...  \n",
       "1  беспокойство сша очевидно тот кто оказаться по...  \n",
       "2  инспирировать сша и поддержать европа « револю...  \n",
       "3  последний отметить алеми наиболее откровенно в...  \n",
       "4  сми иран финляндия не хотеть вступать в нато и...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ent = train[['first', 'second']] \n",
    "#X_test_ent = test[['first', 'second']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_test_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maksim/anaconda/envs/pyNLP/lib/python3.5/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/maksim/anaconda/envs/pyNLP/lib/python3.5/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "#enc.fit(X_ent['first'].append(X_ent['second']).append(X_test_ent['first']).append(X_test_ent['second']))\n",
    "enc.fit(X_ent['first'].append(X_ent['second']))\n",
    "\n",
    "\n",
    "X_ent['first'] = enc.transform(X_ent['first'])\n",
    "X_ent['second'] = enc.transform(X_ent['second'])\n",
    "\n",
    "#X_test_ent['second'] = enc.transform(X_test_ent['second'])\n",
    "#X_test_ent['first'] = enc.transform(X_test_ent['first'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878\n",
      "(878, 2)\n"
     ]
    }
   ],
   "source": [
    "target = list(train['ans'])\n",
    "print(len(target))\n",
    "print(X_ent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i in range(len(target)):\n",
    "    if target[i].strip() == 'neg':\n",
    "        target[i] = 0\n",
    "        counter += 1\n",
    "    else:\n",
    "        target[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(878, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x118009c88>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ent = CatBoostClassifier(iterations = 400, depth=12)\n",
    "model_ent.fit(np.array(X_ent), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans = model_ent.predict(np.array(X_ent[600:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97841726618705038"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(target[600:], ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_file_paths, test_ann_paths = get_source_paths('test/', mod=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [02:04<00:00,  2.94s/it]\n"
     ]
    }
   ],
   "source": [
    "test_data = analize_files_test(ann_paths=test_ann_paths, file_paths=test_file_paths, sent_words=sent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>num_neg</th>\n",
       "      <th>num_pos</th>\n",
       "      <th>second</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>финляндия</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>сша</td>\n",
       "      <td>поддержать президент и министр оборона страна ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>финляндия</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>путин</td>\n",
       "      <td>особый внимание сми привлечь неожиданный вопро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>финляндия</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>франция</td>\n",
       "      <td>поддержать президент и министр оборона страна ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>финляндия</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>запасть</td>\n",
       "      <td>журналист ярмо мякель jarmo makela не понравит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>финляндия</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>таусить</td>\n",
       "      <td>сари таусить sari tausi журналистка финский те...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>финляндия</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>германия</td>\n",
       "      <td>поддержать президент и министр оборона страна ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>финляндия</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>helsingin sanomat</td>\n",
       "      <td>журналист ярмо мякель jarmo makela не понравит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>финляндия</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>россия</td>\n",
       "      <td>сми финляндия мы не нужный совет швеция о тот ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>финляндия</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yle</td>\n",
       "      <td>особый внимание сми привлечь неожиданный вопро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>финляндия</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>сми</td>\n",
       "      <td>сми финляндия мы не нужный совет швеция о тот ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>финляндия</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>норвегия</td>\n",
       "      <td>это в один очередь общий граница финляндия и р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>финляндия</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>мякель</td>\n",
       "      <td>журналист ярмо мякель jarmo makela не понравит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>финляндия</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>швеция</td>\n",
       "      <td>сми финляндия мы не нужный совет швеция о тот ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>финляндия</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mtv</td>\n",
       "      <td>поддержать президент и министр оборона страна ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>финляндия</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ниинистё</td>\n",
       "      <td>особый внимание сми привлечь неожиданный вопро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>финляндия</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>крым</td>\n",
       "      <td>у страна также сильно различаться подход к кры...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>сша</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>франция</td>\n",
       "      <td>поддержать президент и министр оборона страна ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>сша</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>германия</td>\n",
       "      <td>поддержать президент и министр оборона страна ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>сша</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>россия</td>\n",
       "      <td>поддержать президент и министр оборона страна ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>сша</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mtv</td>\n",
       "      <td>поддержать президент и министр оборона страна ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>сша</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ниинистё</td>\n",
       "      <td>поддержать президент и министр оборона страна ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>путин</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>вильякайнный</td>\n",
       "      <td>16 06 пекка вильякайнный pekka viljakainen сов...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>путин</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>россия</td>\n",
       "      <td>16 06 пекка вильякайнный pekka viljakainen сов...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>путин</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yle</td>\n",
       "      <td>особый внимание сми привлечь неожиданный вопро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>путин</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>сми</td>\n",
       "      <td>особый внимание сми привлечь неожиданный вопро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>путин</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>швеция</td>\n",
       "      <td>особый внимание сми привлечь неожиданный вопро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>путин</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>сколково</td>\n",
       "      <td>16 06 пекка вильякайнный pekka viljakainen сов...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>путин</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ниинистё</td>\n",
       "      <td>особый внимание сми привлечь неожиданный вопро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>путин</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>крым</td>\n",
       "      <td>а это проблематично поскольку путин испортить ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>лиухтый</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>turun sanomat</td>\n",
       "      <td>финский профессор карий лиухтый kari liuhto не...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>запасть</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>сми</td>\n",
       "      <td>журналист ярмо мякель jarmo makela не понравит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>запасть</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>мякель</td>\n",
       "      <td>журналист ярмо мякель jarmo makela не понравит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>таусить</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>россия</td>\n",
       "      <td>сари таусить sari tausi журналистка финский те...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>таусить</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yle</td>\n",
       "      <td>сари таусить sari tausi журналистка финский те...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>таусить</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>норвегия</td>\n",
       "      <td>это в один очередь общий граница финляндия и р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>таусить</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>швеция</td>\n",
       "      <td>сари таусить sari tausi журналистка финский те...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>германия</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>россия</td>\n",
       "      <td>поддержать президент и министр оборона страна ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>германия</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mtv</td>\n",
       "      <td>поддержать президент и министр оборона страна ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>германия</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ниинистё</td>\n",
       "      <td>поддержать президент и министр оборона страна ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>helsingin sanomat</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>сми</td>\n",
       "      <td>журналист ярмо мякель jarmo makela не понравит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>helsingin sanomat</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>мякель</td>\n",
       "      <td>журналист ярмо мякель jarmo makela не понравит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>helsingin sanomat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ниинистё</td>\n",
       "      <td>следовать отметить что ниинистё поддержать мно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>россия</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yle</td>\n",
       "      <td>сари таусить sari tausi журналистка финский те...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>россия</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>сми</td>\n",
       "      <td>сми финляндия мы не нужный совет швеция о тот ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>россия</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>норвегия</td>\n",
       "      <td>это в один очередь общий граница финляндия и р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>россия</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>швеция</td>\n",
       "      <td>сми финляндия мы не нужный совет швеция о тот ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>россия</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mtv</td>\n",
       "      <td>поддержать президент и министр оборона страна ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>россия</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>сколково</td>\n",
       "      <td>16 06 пекка вильякайнный pekka viljakainen сов...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>россия</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ниинистё</td>\n",
       "      <td>поддержать президент и министр оборона страна ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>россия</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>крым</td>\n",
       "      <td>у страна также сильно различаться подход к кры...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>yle</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>сми</td>\n",
       "      <td>особый внимание сми привлечь неожиданный вопро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>yle</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>швеция</td>\n",
       "      <td>особый внимание сми привлечь неожиданный вопро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>yle</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ниинистё</td>\n",
       "      <td>особый внимание сми привлечь неожиданный вопро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>сми</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>мякель</td>\n",
       "      <td>журналист ярмо мякель jarmo makela не понравит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>сми</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>швеция</td>\n",
       "      <td>сми финляндия мы не нужный совет швеция о тот ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>сми</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ниинистё</td>\n",
       "      <td>особый внимание сми привлечь неожиданный вопро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>норвегия</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>швеция</td>\n",
       "      <td>это в один очередь общий граница финляндия и р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>швеция</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>ниинистё</td>\n",
       "      <td>особый внимание сми привлечь неожиданный вопро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>швеция</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>крым</td>\n",
       "      <td>у страна также сильно различаться подход к кры...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>mtv</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ниинистё</td>\n",
       "      <td>поддержать президент и министр оборона страна ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                first  num_neg  num_pos             second  \\\n",
       "0           финляндия        1        0                сша   \n",
       "1           финляндия        0        2              путин   \n",
       "2           финляндия        1        0            франция   \n",
       "3           финляндия        1        1            запасть   \n",
       "4           финляндия        0        0            таусить   \n",
       "5           финляндия        1        0           германия   \n",
       "6           финляндия        1        1  helsingin sanomat   \n",
       "7           финляндия        1        2             россия   \n",
       "8           финляндия        0        2                yle   \n",
       "9           финляндия        1        3                сми   \n",
       "10          финляндия        0        0           норвегия   \n",
       "11          финляндия        1        1             мякель   \n",
       "12          финляндия        0        2             швеция   \n",
       "13          финляндия        1        0                mtv   \n",
       "14          финляндия        1        2           ниинистё   \n",
       "15          финляндия        0        0               крым   \n",
       "16                сша        1        0            франция   \n",
       "17                сша        1        0           германия   \n",
       "18                сша        1        0             россия   \n",
       "19                сша        1        0                mtv   \n",
       "20                сша        1        0           ниинистё   \n",
       "21              путин        0        6       вильякайнный   \n",
       "22              путин        0        6             россия   \n",
       "23              путин        0        2                yle   \n",
       "24              путин        0        2                сми   \n",
       "25              путин        0        2             швеция   \n",
       "26              путин        0        6           сколково   \n",
       "27              путин        0        2           ниинистё   \n",
       "28              путин        1        0               крым   \n",
       "29            лиухтый        0        1      turun sanomat   \n",
       "..                ...      ...      ...                ...   \n",
       "38            запасть        1        1                сми   \n",
       "39            запасть        1        1             мякель   \n",
       "40            таусить        0        0             россия   \n",
       "41            таусить        0        0                yle   \n",
       "42            таусить        0        0           норвегия   \n",
       "43            таусить        0        0             швеция   \n",
       "44           германия        1        0             россия   \n",
       "45           германия        1        0                mtv   \n",
       "46           германия        1        0           ниинистё   \n",
       "47  helsingin sanomat        1        1                сми   \n",
       "48  helsingin sanomat        1        1             мякель   \n",
       "49  helsingin sanomat        0        0           ниинистё   \n",
       "50             россия        0        0                yle   \n",
       "51             россия        0        0                сми   \n",
       "52             россия        0        0           норвегия   \n",
       "53             россия        2        1             швеция   \n",
       "54             россия        1        0                mtv   \n",
       "55             россия        0        6           сколково   \n",
       "56             россия        1        0           ниинистё   \n",
       "57             россия        0        0               крым   \n",
       "58                yle        0        2                сми   \n",
       "59                yle        0        2             швеция   \n",
       "60                yle        0        2           ниинистё   \n",
       "61                сми        1        1             мякель   \n",
       "62                сми        0        2             швеция   \n",
       "63                сми        0        2           ниинистё   \n",
       "64           норвегия        0        0             швеция   \n",
       "65             швеция        0        2           ниинистё   \n",
       "66             швеция        0        0               крым   \n",
       "67                mtv        1        0           ниинистё   \n",
       "\n",
       "                                                 sent  \n",
       "0   поддержать президент и министр оборона страна ...  \n",
       "1   особый внимание сми привлечь неожиданный вопро...  \n",
       "2   поддержать президент и министр оборона страна ...  \n",
       "3   журналист ярмо мякель jarmo makela не понравит...  \n",
       "4   сари таусить sari tausi журналистка финский те...  \n",
       "5   поддержать президент и министр оборона страна ...  \n",
       "6   журналист ярмо мякель jarmo makela не понравит...  \n",
       "7   сми финляндия мы не нужный совет швеция о тот ...  \n",
       "8   особый внимание сми привлечь неожиданный вопро...  \n",
       "9   сми финляндия мы не нужный совет швеция о тот ...  \n",
       "10  это в один очередь общий граница финляндия и р...  \n",
       "11  журналист ярмо мякель jarmo makela не понравит...  \n",
       "12  сми финляндия мы не нужный совет швеция о тот ...  \n",
       "13  поддержать президент и министр оборона страна ...  \n",
       "14  особый внимание сми привлечь неожиданный вопро...  \n",
       "15  у страна также сильно различаться подход к кры...  \n",
       "16  поддержать президент и министр оборона страна ...  \n",
       "17  поддержать президент и министр оборона страна ...  \n",
       "18  поддержать президент и министр оборона страна ...  \n",
       "19  поддержать президент и министр оборона страна ...  \n",
       "20  поддержать президент и министр оборона страна ...  \n",
       "21  16 06 пекка вильякайнный pekka viljakainen сов...  \n",
       "22  16 06 пекка вильякайнный pekka viljakainen сов...  \n",
       "23  особый внимание сми привлечь неожиданный вопро...  \n",
       "24  особый внимание сми привлечь неожиданный вопро...  \n",
       "25  особый внимание сми привлечь неожиданный вопро...  \n",
       "26  16 06 пекка вильякайнный pekka viljakainen сов...  \n",
       "27  особый внимание сми привлечь неожиданный вопро...  \n",
       "28  а это проблематично поскольку путин испортить ...  \n",
       "29  финский профессор карий лиухтый kari liuhto не...  \n",
       "..                                                ...  \n",
       "38  журналист ярмо мякель jarmo makela не понравит...  \n",
       "39  журналист ярмо мякель jarmo makela не понравит...  \n",
       "40  сари таусить sari tausi журналистка финский те...  \n",
       "41  сари таусить sari tausi журналистка финский те...  \n",
       "42  это в один очередь общий граница финляндия и р...  \n",
       "43  сари таусить sari tausi журналистка финский те...  \n",
       "44  поддержать президент и министр оборона страна ...  \n",
       "45  поддержать президент и министр оборона страна ...  \n",
       "46  поддержать президент и министр оборона страна ...  \n",
       "47  журналист ярмо мякель jarmo makela не понравит...  \n",
       "48  журналист ярмо мякель jarmo makela не понравит...  \n",
       "49  следовать отметить что ниинистё поддержать мно...  \n",
       "50  сари таусить sari tausi журналистка финский те...  \n",
       "51  сми финляндия мы не нужный совет швеция о тот ...  \n",
       "52  это в один очередь общий граница финляндия и р...  \n",
       "53  сми финляндия мы не нужный совет швеция о тот ...  \n",
       "54  поддержать президент и министр оборона страна ...  \n",
       "55  16 06 пекка вильякайнный pekka viljakainen сов...  \n",
       "56  поддержать президент и министр оборона страна ...  \n",
       "57  у страна также сильно различаться подход к кры...  \n",
       "58  особый внимание сми привлечь неожиданный вопро...  \n",
       "59  особый внимание сми привлечь неожиданный вопро...  \n",
       "60  особый внимание сми привлечь неожиданный вопро...  \n",
       "61  журналист ярмо мякель jarmo makela не понравит...  \n",
       "62  сми финляндия мы не нужный совет швеция о тот ...  \n",
       "63  особый внимание сми привлечь неожиданный вопро...  \n",
       "64  это в один очередь общий граница финляндия и р...  \n",
       "65  особый внимание сми привлечь неожиданный вопро...  \n",
       "66  у страна также сильно различаться подход к кры...  \n",
       "67  поддержать президент и министр оборона страна ...  \n",
       "\n",
       "[68 rows x 5 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_full = pd.concat(test_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5826, 2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ent = train[['first', 'second']] \n",
    "X_test_ent = test_data_full[['first', 'second']]\n",
    "X_test_ent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>609</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>565</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>528</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>528</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>443</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>443</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>443</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>528</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>528</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>702</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>528</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>528</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>528</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>304</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>565</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>528</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>460</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>565</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>565</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>609</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>425</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>425</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>293</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>293</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>293</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>293</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>565</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>565</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>293</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>293</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>528</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>609</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>609</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>609</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>609</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>609</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>609</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>609</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>609</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>609</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>609</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>609</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>609</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>609</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>609</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>609</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>646</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>646</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>646</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>700</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>725</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>443</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>443</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>443</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>443</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>528</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>714</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>390</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>384</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>498</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>878 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     first  second\n",
       "0      609     288\n",
       "1      565     609\n",
       "2      528     609\n",
       "3      528     609\n",
       "4      443     528\n",
       "5      443     528\n",
       "6      443     528\n",
       "7      528     655\n",
       "8      528     655\n",
       "9      702     629\n",
       "10     528     443\n",
       "11     528     443\n",
       "12     528     443\n",
       "13     304     565\n",
       "14     565     304\n",
       "15     528     565\n",
       "16     460     565\n",
       "17     565     528\n",
       "18     565     528\n",
       "19     609      91\n",
       "20     425     293\n",
       "21     425     293\n",
       "22     293     528\n",
       "23     293     528\n",
       "24     293     528\n",
       "25     293     528\n",
       "26     565     293\n",
       "27     565     293\n",
       "28     293     565\n",
       "29     293     565\n",
       "..     ...     ...\n",
       "848    528     646\n",
       "849    609     273\n",
       "850    609     273\n",
       "851    609     273\n",
       "852    609     273\n",
       "853    609     273\n",
       "854    609     273\n",
       "855    609     273\n",
       "856    609     273\n",
       "857    609     273\n",
       "858    609     273\n",
       "859    609     492\n",
       "860    609     492\n",
       "861    609     498\n",
       "862    609     646\n",
       "863    609     646\n",
       "864    646     268\n",
       "865    646     528\n",
       "866    646     528\n",
       "867    700     331\n",
       "868    725     500\n",
       "869    443     498\n",
       "870    443     528\n",
       "871    443     646\n",
       "872    443     686\n",
       "873    528     443\n",
       "874    714     370\n",
       "875    390     370\n",
       "876    384     370\n",
       "877    498     370\n",
       "\n",
       "[878 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maksim/anaconda/envs/pyNLP/lib/python3.5/site-packages/pandas/core/indexing.py:601: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n",
      "/Users/maksim/anaconda/envs/pyNLP/lib/python3.5/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "enc.fit(X_ent['first'].append(X_ent['second']).append(X_test_ent['first']).append(X_test_ent['second']))\n",
    "\n",
    "X_ent.loc[:, 'first'] = enc.transform(X_ent['first'])\n",
    "X_ent.loc[:, 'second'] = enc.transform(X_ent['second'])\n",
    "\n",
    "X_test_ent.loc[:, 'second'] = enc.transform(X_test_ent['second'])\n",
    "X_test_ent.loc[:, 'first'] = enc.transform(X_test_ent['first'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ent.fit(np.array(X_ent), target)\n",
    "ans = model_ent.predict(np.array(X_test_ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2970\n"
     ]
    }
   ],
   "source": [
    "print(len([item for item in ans if item == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             финляндия\n",
       "1             финляндия\n",
       "2             финляндия\n",
       "3             финляндия\n",
       "4             финляндия\n",
       "5             финляндия\n",
       "6             финляндия\n",
       "7             финляндия\n",
       "8             финляндия\n",
       "9             финляндия\n",
       "10            финляндия\n",
       "11            финляндия\n",
       "12            финляндия\n",
       "13            финляндия\n",
       "14            финляндия\n",
       "15            финляндия\n",
       "16                  сша\n",
       "17                  сша\n",
       "18                  сша\n",
       "19                  сша\n",
       "20                  сша\n",
       "21                путин\n",
       "22                путин\n",
       "23                путин\n",
       "24                путин\n",
       "25                путин\n",
       "26                путин\n",
       "27                путин\n",
       "28                путин\n",
       "29              лиухтый\n",
       "30              лиухтый\n",
       "31              франция\n",
       "32              франция\n",
       "33              франция\n",
       "34              франция\n",
       "35         вильякайнный\n",
       "36         вильякайнный\n",
       "37              запасть\n",
       "38              запасть\n",
       "39              запасть\n",
       "40             германия\n",
       "41             германия\n",
       "42             германия\n",
       "43    helsingin sanomat\n",
       "44    helsingin sanomat\n",
       "45               россия\n",
       "46               россия\n",
       "47               россия\n",
       "48               россия\n",
       "49                  yle\n",
       "50                  yle\n",
       "51                  yle\n",
       "52                  сми\n",
       "53                  сми\n",
       "54                  сми\n",
       "55               швеция\n",
       "56                  mtv\n",
       "Name: first, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][['first', 'second']].loc[:, 'first']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LabelEncoder.inverse_transform of LabelEncoder()>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maksim/anaconda/envs/pyNLP/lib/python3.5/site-packages/pandas/core/indexing.py:601: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n",
      "/Users/maksim/anaconda/envs/pyNLP/lib/python3.5/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Users/maksim/anaconda/envs/pyNLP/lib/python3.5/site-packages/pandas/core/indexing.py:337: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/maksim/anaconda/envs/pyNLP/lib/python3.5/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/maksim/anaconda/envs/pyNLP/lib/python3.5/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/Users/maksim/anaconda/envs/pyNLP/lib/python3.5/site-packages/pandas/core/series.py:747: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc[key] = value\n",
      "/Users/maksim/anaconda/envs/pyNLP/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2862: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/maksim/anaconda/envs/pyNLP/lib/python3.5/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/maksim/anaconda/envs/pyNLP/lib/python3.5/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "for el, path in zip(test_data, test_file_paths):\n",
    "    XX = el[['first', 'second']]\n",
    "    #print(XX)\n",
    "    #print(XX.loc['first'])\n",
    "    XX.loc[:, 'first'] = enc.transform(XX['first'])\n",
    "    XX.loc[:, 'second'] = enc.transform(XX['second'])\n",
    "    ans = model_ent.predict(np.array(XX))\n",
    "    #print(ans)\n",
    "    XX.loc[:, 'ans'] = ans\n",
    "    #print(path[5:-4])\n",
    "    XX.loc[:, 'first'] = enc.inverse_transform(XX['first'])\n",
    "    XX.loc[:, 'second'] = enc.inverse_transform(XX['second'])\n",
    "    col_ans = XX['ans'] \n",
    "    for idx, item in col_ans.items():\n",
    "        if col_ans[idx] > 0:\n",
    "            col_ans[idx] = \"pos\"\n",
    "        else:\n",
    "            col_ans[idx] = \"neg\"\n",
    "    #print(col_ans)\n",
    "    XX['ans'] = col_ans\n",
    "    #print(XX)\n",
    "    XX.to_csv('res2/' + path[5:-4] + '.opin.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,  CountVectorizer\n",
    "vect = TfidfVectorizer(ngram_range=(1, 4), min_df=2)\n",
    "vect_c = CountVectorizer(ngram_range=(1, 4), min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tfidf = vect.fit_transform(X)\n",
    "X_count = vect_c.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XX = np.hstack((X_tfidf.toarray(), X_count.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
